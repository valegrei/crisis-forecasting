{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../libs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from utils import shift_data, print_hp,print_line, graficarTodo, split_df, graficarClases, plot_metrics, plot_cm, plot_roc, plot_prc, plot_probs\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import datetime\n",
    "import os\n",
    "import keras_tuner as kt\n",
    "from keras_tuner import HyperModel\n",
    "import keras.metrics as metrics\n",
    "from keras.models import Sequential, load_model, model_from_json\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/PERU_DATA_DIFF.csv')\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "df = df.set_index('DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficarTodo(df,'Features')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mostrar Imbalance de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos = np.bincount(df['Class'])\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficarClases(df['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_bias = np.log([pos/neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividir Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = ['Class']\n",
    "features = df.columns[(df.columns!=target_col[0])]\n",
    "df_train, df_test = split_df(df,0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_train = df_train[features].copy()\n",
    "df_y_train = df_train[target_col].copy()\n",
    "df_x_test = df_test[features].copy()\n",
    "df_y_test = df_test[target_col].copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_x_train.iloc[:,:] = scaler.fit_transform(df_x_train)\n",
    "df_x_test.iloc[:,:] = scaler.transform(df_x_test)\n",
    "\n",
    "df_x_train.iloc[:,:] = np.clip(df_x_train,-5,5)\n",
    "df_x_test.iloc[:,:] = np.clip(df_x_test,-5,5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      metrics.TruePositives(name='tp'),\n",
    "      metrics.FalsePositives(name='fp'),\n",
    "      metrics.TrueNegatives(name='tn'),\n",
    "      metrics.FalseNegatives(name='fn'), \n",
    "      metrics.BinaryAccuracy(name='accuracy'),\n",
    "      metrics.Precision(name='precision'),\n",
    "      metrics.Recall(name='recall'),\n",
    "      metrics.AUC(name='auc'),\n",
    "      metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tuning_model(base_model_path, hp, n_features):\n",
    "    base_model = load_model(base_model_path)\n",
    "    #print(base_model.layers[0].input_shape)\n",
    "    new_model = base_model\n",
    "        #print(len(new_model.layers))\n",
    "        #for layer in new_model.layers[:-1]:\n",
    "        #    layer.trainable = False\n",
    "    new_model.compile(optimizer=Adam(learning_rate=1e-3),\n",
    "                loss=BinaryCrossentropy(), metrics=METRICS)\n",
    "    return new_model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_out = [1,6,12]\n",
    "n_features = len(features)\n",
    "fecha_hora = datetime.datetime.now().strftime('%Y%m%d_%H%M')\n",
    "n_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_model = 'modelos/'\n",
    "name_prj = 'GRU_TL_PERU_'\n",
    "N = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps = [\n",
    "    {'steps_in': 6},\n",
    "    {'steps_in': 6},\n",
    "    {'steps_in': 9},\n",
    "]\n",
    "base_models = [\n",
    "    'modelos/GRU_USA_1_20221230_1705_19.h5',\n",
    "    'modelos/GRU_USA_6_20221230_1705_0.h5',\n",
    "    'modelos/GRU_USA_12_20221230_1717_8.h5',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar(name_prj, n_steps_out, base_model_path, hp):\n",
    "    name_prj = name_prj + str(n_steps_out) +'_'+fecha_hora\n",
    "\n",
    "    # --------------------- Entrenamiento --------------------------------------\n",
    "    n_steps_in = hp['steps_in']\n",
    "    x_train, y_train = shift_data(df_x_train, df_y_train, n_steps_in, n_steps_out)\n",
    "    x_test, y_test = shift_data(df_x_test, df_y_test, n_steps_in, n_steps_out)\n",
    "    batch_learning = len(x_train)\n",
    "\n",
    "    prcs = []\n",
    "    models = []\n",
    "    res_path = output_path_model+name_prj+\".csv\"\n",
    "    print_line(\"loss,tp,fp,tn,fn,accuracy,precision,recall,auc,prc\\n\",res_path)\n",
    "\n",
    "    print(\"Entrenando...\")\n",
    "    for i in range(N):\n",
    "        name_model = output_path_model+name_prj+'_'+str(i)+'.h5'\n",
    "        gru_model = fine_tuning_model(base_model_path, hp, n_features)\n",
    "        # Condicion de parada: 10 epocas despues del menor val_loss\n",
    "        es_t = EarlyStopping(\n",
    "            monitor='val_prc', \n",
    "            verbose=0,\n",
    "            patience=50,\n",
    "            mode='max',\n",
    "            restore_best_weights=True)\n",
    "\n",
    "        models.append(name_model)\n",
    "        gru_model.fit(x=x_train, y=y_train, validation_split = 0.5, epochs = n_epochs\n",
    "            , verbose = 0, shuffle = False, callbacks = [es_t], \n",
    "            batch_size = batch_learning, class_weight = class_weight)\n",
    "\n",
    "        gru_model.save(name_model) \n",
    "        # --------------------- Evaluacion --------------------------------------\n",
    "        res = gru_model.evaluate(x_test, y_test,\n",
    "                                        batch_size=batch_learning, verbose=0)\n",
    "        print_line(f'{res[0]},{res[1]},{res[2]},{res[3]},{res[4]},{res[5]},{res[6]},{res[7]},{res[8]},{res[9]}\\n', res_path)\n",
    "        prcs.append(res[9]) #guarda metrica a comparar\n",
    "    \n",
    "    #--------- Evaluando el mejor ------------------------\n",
    "    print(\"Evaluando mejor...\")\n",
    "    best_model = models[np.argmax(prcs)]\n",
    "    print(f'\\nMejor modelo: {best_model} con prc: {np.max(prcs)}\\n')\n",
    "    for i in range(N):\n",
    "        if i == np.argmax(prcs):\n",
    "            continue\n",
    "        os.remove(models[i])\n",
    "\n",
    "    gru_model = load_model(best_model)\n",
    "    train_predictions = gru_model(x_train) #, batch_size=batch_learning\n",
    "    test_predictions = gru_model(x_test)\n",
    "\n",
    "    plot_cm(y_test, test_predictions)\n",
    "    plot_roc(y_train, train_predictions, y_test, test_predictions)\n",
    "    plot_prc(y_train, train_predictions, y_test, test_predictions)\n",
    "    plot_probs(y_train, train_predictions, 'Train')\n",
    "    plot_probs(y_test, test_predictions, 'Test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo para 1 mes a futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenar(name_prj, n_steps_out[0], base_models[0], hps[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo para 6 meses a futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenar(name_prj, n_steps_out[1], base_models[1], hps[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo para 12 meses a futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenar(name_prj, n_steps_out[2], base_models[2], hps[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6822839c80bb80c42f7f9e096efdd447a89633a8e8a553b5cfb2012f3a4eafe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
